{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c29b63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "pretrained_model = VGG16(include_top=True, weights='imagenet')\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54d9f5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9469 images belonging to 10 classes.\n",
      "Found 3925 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create a new generator\n",
    "imagegen = ImageDataGenerator()\n",
    "# load train data\n",
    "batch_size = 1\n",
    "train = imagegen.flow_from_directory(\"imagenette2/train/\", class_mode=\"categorical\", shuffle=True, batch_size=batch_size, target_size=(224, 224))\n",
    "# load val data\n",
    "val = imagegen.flow_from_directory(\"imagenette2/val/\", class_mode=\"categorical\", shuffle=True, batch_size=batch_size, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a91c65f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "flatten_output = tf.keras.backend.function(pretrained_model.input, pretrained_model.get_layer('flatten').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "657686e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "extracted_train_features_ = []\n",
    "labels = []\n",
    "train_size = 9469\n",
    "from IPython.display import clear_output\n",
    "epochs = int(train_size/batch_size)\n",
    "for i in range(epochs):\n",
    "    print(((i+1)/epochs)*100)\n",
    "    clear_output(wait=True)\n",
    "    xs,ys = train.next()\n",
    "    x = flatten_output(xs)\n",
    "    extracted_train_features_.append(x)\n",
    "    labels.append(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e85be2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 762\n",
      "(9469, 25088)\n",
      "(9469, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(extracted_train_features_)\n",
    "y = np.array(labels)\n",
    "y = np.squeeze(y,axis=1)\n",
    "x = np.squeeze(x,axis=1)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d855238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7575 samples, validate on 1894 samples\n",
      "Epoch 1/100\n",
      "7575/7575 [==============================] - 1s 97us/sample - loss: 1.3432 - acc: 0.3486 - val_loss: 1.2325 - val_acc: 0.5723\n",
      "Epoch 2/100\n",
      "7575/7575 [==============================] - 1s 67us/sample - loss: 1.1979 - acc: 0.6367 - val_loss: 1.1559 - val_acc: 0.7027\n",
      "Epoch 3/100\n",
      "7575/7575 [==============================] - 1s 72us/sample - loss: 1.1370 - acc: 0.7368 - val_loss: 1.1150 - val_acc: 0.7682\n",
      "Epoch 4/100\n",
      "7575/7575 [==============================] - 1s 67us/sample - loss: 1.1054 - acc: 0.7806 - val_loss: 1.0939 - val_acc: 0.7914\n",
      "Epoch 5/100\n",
      "7575/7575 [==============================] - 1s 72us/sample - loss: 1.0812 - acc: 0.8144 - val_loss: 1.0797 - val_acc: 0.8015\n",
      "Epoch 6/100\n",
      "7575/7575 [==============================] - 1s 69us/sample - loss: 1.0701 - acc: 0.8182 - val_loss: 1.0651 - val_acc: 0.8147\n",
      "Epoch 7/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 1.0521 - acc: 0.8409 - val_loss: 1.0525 - val_acc: 0.8273\n",
      "Epoch 8/100\n",
      "7575/7575 [==============================] - 1s 68us/sample - loss: 1.0438 - acc: 0.8411 - val_loss: 1.0452 - val_acc: 0.8237\n",
      "Epoch 9/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 1.0331 - acc: 0.8482 - val_loss: 1.0357 - val_acc: 0.8289\n",
      "Epoch 10/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 1.0227 - acc: 0.8564 - val_loss: 1.0279 - val_acc: 0.8326\n",
      "Epoch 11/100\n",
      "7575/7575 [==============================] - 1s 69us/sample - loss: 1.0151 - acc: 0.8593 - val_loss: 1.0237 - val_acc: 0.8284\n",
      "Epoch 12/100\n",
      "7575/7575 [==============================] - 1s 75us/sample - loss: 1.0085 - acc: 0.8622 - val_loss: 1.0174 - val_acc: 0.8321\n",
      "Epoch 13/100\n",
      "7575/7575 [==============================] - 1s 70us/sample - loss: 1.0051 - acc: 0.8595 - val_loss: 1.0142 - val_acc: 0.8310\n",
      "Epoch 14/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 1.0025 - acc: 0.8589 - val_loss: 1.0137 - val_acc: 0.8263\n",
      "Epoch 15/100\n",
      "7575/7575 [==============================] - 1s 79us/sample - loss: 0.9995 - acc: 0.8605 - val_loss: 1.0097 - val_acc: 0.8310\n",
      "Epoch 16/100\n",
      "7575/7575 [==============================] - 1s 88us/sample - loss: 0.9967 - acc: 0.8624 - val_loss: 1.0079 - val_acc: 0.8316\n",
      "Epoch 17/100\n",
      "7575/7575 [==============================] - 1s 75us/sample - loss: 0.9941 - acc: 0.8647 - val_loss: 1.0056 - val_acc: 0.8321\n",
      "Epoch 18/100\n",
      "7575/7575 [==============================] - 1s 87us/sample - loss: 0.9930 - acc: 0.8647 - val_loss: 1.0091 - val_acc: 0.8242\n",
      "Epoch 19/100\n",
      "7575/7575 [==============================] - 1s 77us/sample - loss: 0.9925 - acc: 0.8663 - val_loss: 1.0086 - val_acc: 0.8258\n",
      "Epoch 20/100\n",
      "7575/7575 [==============================] - 1s 69us/sample - loss: 0.9930 - acc: 0.8671 - val_loss: 1.0061 - val_acc: 0.8347\n",
      "Epoch 21/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 0.9936 - acc: 0.8675 - val_loss: 1.0192 - val_acc: 0.8046\n",
      "Epoch 22/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 0.9973 - acc: 0.8631 - val_loss: 1.0164 - val_acc: 0.8189\n",
      "Epoch 23/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 1.0032 - acc: 0.8556 - val_loss: 1.0258 - val_acc: 0.8041\n",
      "Epoch 24/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 1.0116 - acc: 0.8442 - val_loss: 1.0293 - val_acc: 0.8089\n",
      "Epoch 25/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 1.0124 - acc: 0.8564 - val_loss: 1.0399 - val_acc: 0.7936\n",
      "Epoch 26/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 1.0157 - acc: 0.8554 - val_loss: 1.0313 - val_acc: 0.8152\n",
      "Epoch 27/100\n",
      "7575/7575 [==============================] - 1s 72us/sample - loss: 1.0142 - acc: 0.8593 - val_loss: 1.0270 - val_acc: 0.8237\n",
      "Epoch 28/100\n",
      "7575/7575 [==============================] - 1s 84us/sample - loss: 1.0095 - acc: 0.8665 - val_loss: 1.0291 - val_acc: 0.8115\n",
      "Epoch 29/100\n",
      "7575/7575 [==============================] - 1s 82us/sample - loss: 1.0082 - acc: 0.8630 - val_loss: 1.0203 - val_acc: 0.8268\n",
      "Epoch 30/100\n",
      "7575/7575 [==============================] - 1s 83us/sample - loss: 1.0014 - acc: 0.8717 - val_loss: 1.0213 - val_acc: 0.8157\n",
      "Epoch 31/100\n",
      "7575/7575 [==============================] - 1s 82us/sample - loss: 0.9994 - acc: 0.8698 - val_loss: 1.0164 - val_acc: 0.8215\n",
      "Epoch 32/100\n",
      "7575/7575 [==============================] - 1s 70us/sample - loss: 0.9979 - acc: 0.8683 - val_loss: 1.0159 - val_acc: 0.8194\n",
      "Epoch 33/100\n",
      "7575/7575 [==============================] - 1s 74us/sample - loss: 0.9938 - acc: 0.8727 - val_loss: 1.0096 - val_acc: 0.8279\n",
      "Epoch 34/100\n",
      "7575/7575 [==============================] - 1s 68us/sample - loss: 0.9902 - acc: 0.8767 - val_loss: 1.0069 - val_acc: 0.8310\n",
      "Epoch 35/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 0.9885 - acc: 0.8771 - val_loss: 1.0067 - val_acc: 0.8284\n",
      "Epoch 36/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 0.9860 - acc: 0.8795 - val_loss: 1.0071 - val_acc: 0.8231\n",
      "Epoch 37/100\n",
      "7575/7575 [==============================] - 1s 72us/sample - loss: 0.9847 - acc: 0.8783 - val_loss: 0.9988 - val_acc: 0.8384\n",
      "Epoch 38/100\n",
      "7575/7575 [==============================] - 1s 70us/sample - loss: 0.9819 - acc: 0.8808 - val_loss: 1.0007 - val_acc: 0.8284\n",
      "Epoch 39/100\n",
      "7575/7575 [==============================] - 1s 75us/sample - loss: 0.9808 - acc: 0.8792 - val_loss: 1.0042 - val_acc: 0.8194\n",
      "Epoch 40/100\n",
      "7575/7575 [==============================] - 1s 70us/sample - loss: 0.9806 - acc: 0.8785 - val_loss: 1.0027 - val_acc: 0.8237\n",
      "Epoch 41/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 0.9811 - acc: 0.8778 - val_loss: 1.0008 - val_acc: 0.8268\n",
      "Epoch 42/100\n",
      "7575/7575 [==============================] - 1s 69us/sample - loss: 0.9850 - acc: 0.8688 - val_loss: 0.9997 - val_acc: 0.8342\n",
      "Epoch 43/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 0.9884 - acc: 0.8653 - val_loss: 1.0092 - val_acc: 0.8178\n",
      "Epoch 44/100\n",
      "7575/7575 [==============================] - 1s 72us/sample - loss: 0.9928 - acc: 0.8626 - val_loss: 1.0154 - val_acc: 0.8136\n",
      "Epoch 45/100\n",
      "7575/7575 [==============================] - 1s 67us/sample - loss: 1.0001 - acc: 0.8572 - val_loss: 1.0293 - val_acc: 0.7946\n",
      "Epoch 46/100\n",
      "7575/7575 [==============================] - 1s 72us/sample - loss: 1.0082 - acc: 0.8554 - val_loss: 1.0279 - val_acc: 0.8163\n",
      "Epoch 47/100\n",
      "7575/7575 [==============================] - 1s 67us/sample - loss: 1.0124 - acc: 0.8603 - val_loss: 1.0262 - val_acc: 0.8326\n",
      "Epoch 48/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 1.0138 - acc: 0.8672 - val_loss: 1.0382 - val_acc: 0.8115\n",
      "Epoch 49/100\n",
      "7575/7575 [==============================] - 1s 67us/sample - loss: 1.0184 - acc: 0.8642 - val_loss: 1.0399 - val_acc: 0.8136\n",
      "Epoch 50/100\n",
      "7575/7575 [==============================] - 1s 72us/sample - loss: 1.0205 - acc: 0.8642 - val_loss: 1.0422 - val_acc: 0.8105\n",
      "Epoch 51/100\n",
      "7575/7575 [==============================] - 1s 67us/sample - loss: 1.0208 - acc: 0.8639 - val_loss: 1.0440 - val_acc: 0.8036\n",
      "Epoch 52/100\n",
      "7575/7575 [==============================] - 1s 75us/sample - loss: 1.0213 - acc: 0.8595 - val_loss: 1.0391 - val_acc: 0.8131\n",
      "Epoch 53/100\n",
      "7575/7575 [==============================] - 1s 68us/sample - loss: 1.0188 - acc: 0.8644 - val_loss: 1.0377 - val_acc: 0.8178\n",
      "Epoch 54/100\n",
      "7575/7575 [==============================] - 1s 80us/sample - loss: 1.0200 - acc: 0.8640 - val_loss: 1.0424 - val_acc: 0.8115\n",
      "Epoch 55/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 1.0325 - acc: 0.8424 - val_loss: 1.0520 - val_acc: 0.8046\n",
      "Epoch 56/100\n",
      "7575/7575 [==============================] - 1s 75us/sample - loss: 1.0448 - acc: 0.8285 - val_loss: 1.0702 - val_acc: 0.7746\n",
      "Epoch 57/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 1.0470 - acc: 0.8375 - val_loss: 1.0641 - val_acc: 0.8020\n",
      "Epoch 58/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 1.0520 - acc: 0.8358 - val_loss: 1.0820 - val_acc: 0.7687\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7575/7575 [==============================] - 1s 74us/sample - loss: 1.0573 - acc: 0.8346 - val_loss: 1.0740 - val_acc: 0.7967\n",
      "Epoch 60/100\n",
      "7575/7575 [==============================] - 1s 69us/sample - loss: 1.0517 - acc: 0.8539 - val_loss: 1.0694 - val_acc: 0.8089\n",
      "Epoch 61/100\n",
      "7575/7575 [==============================] - 1s 74us/sample - loss: 1.0536 - acc: 0.8475 - val_loss: 1.0653 - val_acc: 0.8131\n",
      "Epoch 62/100\n",
      "7575/7575 [==============================] - 1s 68us/sample - loss: 1.0549 - acc: 0.8379 - val_loss: 1.0706 - val_acc: 0.7941\n",
      "Epoch 63/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 1.0534 - acc: 0.8371 - val_loss: 1.0656 - val_acc: 0.8041\n",
      "Epoch 64/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 1.0473 - acc: 0.8470 - val_loss: 1.0622 - val_acc: 0.8046\n",
      "Epoch 65/100\n",
      "7575/7575 [==============================] - 1s 70us/sample - loss: 1.0428 - acc: 0.8512 - val_loss: 1.0559 - val_acc: 0.8147\n",
      "Epoch 66/100\n",
      "7575/7575 [==============================] - 1s 72us/sample - loss: 1.0386 - acc: 0.8550 - val_loss: 1.0492 - val_acc: 0.8237\n",
      "Epoch 67/100\n",
      "7575/7575 [==============================] - 1s 70us/sample - loss: 1.0326 - acc: 0.8630 - val_loss: 1.0486 - val_acc: 0.8168\n",
      "Epoch 68/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 1.0280 - acc: 0.8659 - val_loss: 1.0417 - val_acc: 0.8237\n",
      "Epoch 69/100\n",
      "7575/7575 [==============================] - 1s 68us/sample - loss: 1.0233 - acc: 0.8668 - val_loss: 1.0399 - val_acc: 0.8184\n",
      "Epoch 70/100\n",
      "7575/7575 [==============================] - 1s 75us/sample - loss: 1.0207 - acc: 0.8635 - val_loss: 1.0323 - val_acc: 0.8268\n",
      "Epoch 71/100\n",
      "7575/7575 [==============================] - 1s 69us/sample - loss: 1.0139 - acc: 0.8702 - val_loss: 1.0296 - val_acc: 0.8231\n",
      "Epoch 72/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 1.0109 - acc: 0.8684 - val_loss: 1.0251 - val_acc: 0.8273\n",
      "Epoch 73/100\n",
      "7575/7575 [==============================] - 1s 67us/sample - loss: 1.0070 - acc: 0.8708 - val_loss: 1.0295 - val_acc: 0.8099\n",
      "Epoch 74/100\n",
      "7575/7575 [==============================] - 1s 74us/sample - loss: 1.0061 - acc: 0.8664 - val_loss: 1.0196 - val_acc: 0.8263\n",
      "Epoch 75/100\n",
      "7575/7575 [==============================] - 1s 68us/sample - loss: 1.0003 - acc: 0.8729 - val_loss: 1.0172 - val_acc: 0.8247\n",
      "Epoch 76/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 0.9969 - acc: 0.8735 - val_loss: 1.0128 - val_acc: 0.8279\n",
      "Epoch 77/100\n",
      "7575/7575 [==============================] - 1s 68us/sample - loss: 0.9947 - acc: 0.8725 - val_loss: 1.0147 - val_acc: 0.8200\n",
      "Epoch 78/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 0.9943 - acc: 0.8701 - val_loss: 1.0107 - val_acc: 0.8273\n",
      "Epoch 79/100\n",
      "7575/7575 [==============================] - 1s 69us/sample - loss: 0.9924 - acc: 0.8723 - val_loss: 1.0073 - val_acc: 0.8326\n",
      "Epoch 80/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 0.9898 - acc: 0.8772 - val_loss: 1.0089 - val_acc: 0.8273\n",
      "Epoch 81/100\n",
      "7575/7575 [==============================] - 1s 70us/sample - loss: 0.9915 - acc: 0.8717 - val_loss: 1.0100 - val_acc: 0.8263\n",
      "Epoch 82/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 0.9920 - acc: 0.8750 - val_loss: 1.0107 - val_acc: 0.8279\n",
      "Epoch 83/100\n",
      "7575/7575 [==============================] - 1s 71us/sample - loss: 0.9940 - acc: 0.8706 - val_loss: 1.0134 - val_acc: 0.8200\n",
      "Epoch 84/100\n",
      "7575/7575 [==============================] - 1s 69us/sample - loss: 0.9924 - acc: 0.8730 - val_loss: 1.0093 - val_acc: 0.8295\n",
      "Epoch 85/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 0.9924 - acc: 0.8735 - val_loss: 1.0092 - val_acc: 0.8289\n",
      "Epoch 86/100\n",
      "7575/7575 [==============================] - 1s 68us/sample - loss: 0.9906 - acc: 0.8751 - val_loss: 1.0062 - val_acc: 0.8342\n",
      "Epoch 87/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 0.9895 - acc: 0.8755 - val_loss: 1.0070 - val_acc: 0.8279\n",
      "Epoch 88/100\n",
      "7575/7575 [==============================] - 1s 69us/sample - loss: 0.9886 - acc: 0.8750 - val_loss: 1.0094 - val_acc: 0.8247\n",
      "Epoch 89/100\n",
      "7575/7575 [==============================] - 1s 76us/sample - loss: 0.9925 - acc: 0.8676 - val_loss: 1.0167 - val_acc: 0.8099\n",
      "Epoch 90/100\n",
      "7575/7575 [==============================] - 1s 70us/sample - loss: 0.9962 - acc: 0.8632 - val_loss: 1.0119 - val_acc: 0.8258\n",
      "Epoch 91/100\n",
      "7575/7575 [==============================] - 1s 72us/sample - loss: 1.0035 - acc: 0.8494 - val_loss: 1.0157 - val_acc: 0.8242\n",
      "Epoch 92/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 1.0004 - acc: 0.8644 - val_loss: 1.0273 - val_acc: 0.8004\n",
      "Epoch 93/100\n",
      "7575/7575 [==============================] - 1s 72us/sample - loss: 1.0033 - acc: 0.8617 - val_loss: 1.0215 - val_acc: 0.8152\n",
      "Epoch 94/100\n",
      "7575/7575 [==============================] - 1s 70us/sample - loss: 1.0023 - acc: 0.8639 - val_loss: 1.0185 - val_acc: 0.8215\n",
      "Epoch 95/100\n",
      "7575/7575 [==============================] - 1s 70us/sample - loss: 1.0013 - acc: 0.8652 - val_loss: 1.0153 - val_acc: 0.8284\n",
      "Epoch 96/100\n",
      "7575/7575 [==============================] - 1s 70us/sample - loss: 0.9978 - acc: 0.8730 - val_loss: 1.0183 - val_acc: 0.8173\n",
      "Epoch 97/100\n",
      "7575/7575 [==============================] - 1s 73us/sample - loss: 0.9961 - acc: 0.8730 - val_loss: 1.0147 - val_acc: 0.8221\n",
      "Epoch 98/100\n",
      "7575/7575 [==============================] - 1s 74us/sample - loss: 0.9950 - acc: 0.8704 - val_loss: 1.0096 - val_acc: 0.8310\n",
      "Epoch 99/100\n",
      "7575/7575 [==============================] - 1s 66us/sample - loss: 0.9918 - acc: 0.8750 - val_loss: 1.0118 - val_acc: 0.8210\n",
      "Epoch 100/100\n",
      "7575/7575 [==============================] - 1s 74us/sample - loss: 0.9917 - acc: 0.8745 - val_loss: 1.0146 - val_acc: 0.8173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c42a0a9588>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "model = Sequential()\n",
    "model.add(Dense(10, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation\n",
    "             ='softmax',input_shape=(25088,)))\n",
    "model.compile(optimizer = 'adam', loss = 'squared_hinge', metrics = ['accuracy'])\n",
    "model.fit(x,y, epochs=100, batch_size=1500, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b777b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3925, 25088)\n",
      "(3925, 10)\n"
     ]
    }
   ],
   "source": [
    "xtest = []\n",
    "ytest = []\n",
    "test_size = 3925\n",
    "epochs = int(test_size/batch_size)\n",
    "for i in range(epochs):\n",
    "    print(((i+1)/epochs)*100)\n",
    "    clear_output(wait=True)\n",
    "    xs,xy = val.next()\n",
    "    x = flatten_output(xs)\n",
    "    xtest.append(x)\n",
    "    ytest.append(xy)\n",
    "\n",
    "x_test = np.array(xtest)\n",
    "y_test = np.array(ytest)\n",
    "x_test = np.squeeze(x_test,axis=1)\n",
    "y_test = np.squeeze(y_test,axis=1)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13d4018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 82us/sample - loss: 1.0206 - acc: 0.8025\n",
      "Test results - Loss: 1.020605990409851 - Accuracy: 80.25000095367432%\n"
     ]
    }
   ],
   "source": [
    "random_index = np.random.randint(low=0,high=test_size-1,size=2000)\n",
    "\n",
    "test_results = model.evaluate(x_test[random_index], y_test[random_index], verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b6167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7987fc39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
